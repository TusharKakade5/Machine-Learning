{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T13:38:18.119900Z",
     "start_time": "2021-06-02T13:38:16.544341Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T13:38:18.766180Z",
     "start_time": "2021-06-02T13:38:18.727696Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T13:38:19.983098Z",
     "start_time": "2021-06-02T13:38:19.941757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T13:51:11.900557Z",
     "start_time": "2021-06-02T13:51:11.890468Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1',axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T13:51:13.819004Z",
     "start_time": "2021-06-02T13:51:13.608616Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T13:51:14.601205Z",
     "start_time": "2021-06-02T13:51:14.579694Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T13:52:24.806018Z",
     "start_time": "2021-06-02T13:52:24.796994Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T14:04:40.230728Z",
     "start_time": "2021-06-02T14:04:40.224718Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler_std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T14:05:18.948657Z",
     "start_time": "2021-06-02T14:05:18.935148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)\n",
    "scaler_std.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T15:50:20.402107Z",
     "start_time": "2021-06-02T15:50:20.354425Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T15:51:05.220063Z",
     "start_time": "2021-06-02T15:50:57.501153Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T15:54:01.456952Z",
     "start_time": "2021-06-02T15:54:01.437006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T03:17:27.185181Z",
     "start_time": "2021-06-03T03:17:26.000460Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model \n",
    "\n",
    "### Example One: Choosing too many epochs and overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T03:18:51.434131Z",
     "start_time": "2021-06-03T03:18:20.792704Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 0.6741 - val_loss: 0.6556\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6449 - val_loss: 0.6245\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 0.5843\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5603 - val_loss: 0.5308\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5116 - val_loss: 0.4712\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4672 - val_loss: 0.4087\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3978 - val_loss: 0.3565\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3327 - val_loss: 0.3104\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.2797\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2745 - val_loss: 0.2491\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2640 - val_loss: 0.2294\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2373 - val_loss: 0.2087\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2249 - val_loss: 0.1955\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2122 - val_loss: 0.1836\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1873 - val_loss: 0.1749\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1752 - val_loss: 0.1669\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1961 - val_loss: 0.1596\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1738 - val_loss: 0.1544\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1699 - val_loss: 0.1485\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1404 - val_loss: 0.1464\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1392 - val_loss: 0.1375\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1250 - val_loss: 0.1413\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1323 - val_loss: 0.1319\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1288 - val_loss: 0.1293\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1254 - val_loss: 0.1260\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1038 - val_loss: 0.1245\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0977 - val_loss: 0.1256\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1034 - val_loss: 0.1191\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 0.1165\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0919 - val_loss: 0.1214\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1105 - val_loss: 0.1150\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0890 - val_loss: 0.1154\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0948 - val_loss: 0.1156\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0949 - val_loss: 0.1136\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0802 - val_loss: 0.1149\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.1137\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.1142\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0930 - val_loss: 0.1119\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0974 - val_loss: 0.1113\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0757 - val_loss: 0.1114\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0694 - val_loss: 0.1123\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0719 - val_loss: 0.1124\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0846 - val_loss: 0.1091\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0607 - val_loss: 0.1163\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0706 - val_loss: 0.1114\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.1152\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0713 - val_loss: 0.1066\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.1163\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.1085\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0569 - val_loss: 0.1174\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0612 - val_loss: 0.1094\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0783 - val_loss: 0.1102\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0558 - val_loss: 0.1123\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0705 - val_loss: 0.1101\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0611 - val_loss: 0.1101\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0559 - val_loss: 0.1125\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0621 - val_loss: 0.1117\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0553 - val_loss: 0.1155\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0665 - val_loss: 0.1139\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.1151\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0617 - val_loss: 0.1097\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0621 - val_loss: 0.1142\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0581 - val_loss: 0.1122\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0847 - val_loss: 0.1107\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0489 - val_loss: 0.1129\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0522 - val_loss: 0.1132\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0579 - val_loss: 0.1075\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0527 - val_loss: 0.1187\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.1091\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.1248\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.1117\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.1202\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0619 - val_loss: 0.1184\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0538 - val_loss: 0.1157\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0702 - val_loss: 0.1142\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0753 - val_loss: 0.1100\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0580 - val_loss: 0.1404\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0551 - val_loss: 0.1092\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.1159\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0534 - val_loss: 0.1194\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0533 - val_loss: 0.1131\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0519 - val_loss: 0.1180\n",
      "Epoch 83/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0591 - val_loss: 0.1141\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0471 - val_loss: 0.1173\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0478 - val_loss: 0.1136\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.1263\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.1155\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0471 - val_loss: 0.1227\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0565 - val_loss: 0.1155\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0597 - val_loss: 0.1213\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0363 - val_loss: 0.1171\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0463 - val_loss: 0.1228\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0435 - val_loss: 0.1232\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0533 - val_loss: 0.1166\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0512 - val_loss: 0.1176\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0435 - val_loss: 0.1222\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.1227\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.1236\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.1221\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0466 - val_loss: 0.1266\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0431 - val_loss: 0.1276\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.1207\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.1220\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0387 - val_loss: 0.1179\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.1292\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.1172\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.1315\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.1189\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.1323\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.1289\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.1227\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.1309\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0484 - val_loss: 0.1213\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.1301\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0349 - val_loss: 0.1257\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.1214\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0327 - val_loss: 0.1402\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0344 - val_loss: 0.1246\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0438 - val_loss: 0.1370\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0520 - val_loss: 0.1223\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0360 - val_loss: 0.1296\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.1197\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.1526\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.1202\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0402 - val_loss: 0.1397\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0371 - val_loss: 0.1219\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0459 - val_loss: 0.1388\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.1223\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0344 - val_loss: 0.1304\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0412 - val_loss: 0.1299\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.1316\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.1254\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.1327\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.1302\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.1318\n",
      "Epoch 136/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.1482\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.1261\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.1318\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.1222\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.1380\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.1326\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.1305\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0321 - val_loss: 0.1310\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.1346\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0454 - val_loss: 0.1321\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.1299\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.1618\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.1299\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.1618\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.1231\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.1451\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0431 - val_loss: 0.1321\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.1509\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.1332\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.1416\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.1382\n",
      "Epoch 157/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.1398\n",
      "Epoch 158/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.1473\n",
      "Epoch 159/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.1354\n",
      "Epoch 160/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.1375\n",
      "Epoch 161/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.1445\n",
      "Epoch 162/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.1492\n",
      "Epoch 163/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.1419\n",
      "Epoch 164/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.1412\n",
      "Epoch 165/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.1422\n",
      "Epoch 166/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.1389\n",
      "Epoch 167/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.1365\n",
      "Epoch 168/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.1425\n",
      "Epoch 169/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.1405\n",
      "Epoch 170/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.1366\n",
      "Epoch 171/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.1402\n",
      "Epoch 172/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.1420\n",
      "Epoch 173/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.1367\n",
      "Epoch 174/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.1408\n",
      "Epoch 175/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.1352\n",
      "Epoch 176/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.1459\n",
      "Epoch 177/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.1406\n",
      "Epoch 178/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.1432\n",
      "Epoch 179/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.1506\n",
      "Epoch 180/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.1393\n",
      "Epoch 181/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.1470\n",
      "Epoch 182/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.1409\n",
      "Epoch 183/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.1436\n",
      "Epoch 184/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.1520\n",
      "Epoch 185/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.1417\n",
      "Epoch 186/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.1407\n",
      "Epoch 187/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.1442\n",
      "Epoch 188/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.1393\n",
      "Epoch 189/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.1470\n",
      "Epoch 190/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.1382\n",
      "Epoch 191/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.1461\n",
      "Epoch 192/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.1400\n",
      "Epoch 193/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.1384\n",
      "Epoch 194/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.1415\n",
      "Epoch 195/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.1451\n",
      "Epoch 196/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.1502\n",
      "Epoch 197/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.1489\n",
      "Epoch 198/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.1492\n",
      "Epoch 199/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.1444\n",
      "Epoch 200/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.1428\n",
      "Epoch 201/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.1446\n",
      "Epoch 202/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.1406\n",
      "Epoch 203/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.1338\n",
      "Epoch 204/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.1560\n",
      "Epoch 205/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.1465\n",
      "Epoch 206/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.1490\n",
      "Epoch 207/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.1595\n",
      "Epoch 208/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.1467\n",
      "Epoch 209/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.1625\n",
      "Epoch 210/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.1414\n",
      "Epoch 211/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.1602\n",
      "Epoch 212/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.1376\n",
      "Epoch 213/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.1547\n",
      "Epoch 214/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.1428\n",
      "Epoch 215/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.1489\n",
      "Epoch 216/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.1502\n",
      "Epoch 217/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.1565\n",
      "Epoch 218/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.1454\n",
      "Epoch 219/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.1445\n",
      "Epoch 220/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.1413\n",
      "Epoch 221/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.1637\n",
      "Epoch 222/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.1369\n",
      "Epoch 223/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.1774\n",
      "Epoch 224/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.1277\n",
      "Epoch 225/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.1654\n",
      "Epoch 226/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.1397\n",
      "Epoch 227/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.1564\n",
      "Epoch 228/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.1429\n",
      "Epoch 229/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.1449\n",
      "Epoch 230/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.1512\n",
      "Epoch 231/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 0.1368\n",
      "Epoch 232/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.1480\n",
      "Epoch 233/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.1517\n",
      "Epoch 234/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.1461\n",
      "Epoch 235/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.1469\n",
      "Epoch 236/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.1604\n",
      "Epoch 237/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.1424\n",
      "Epoch 238/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.1970\n",
      "Epoch 239/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0319 - val_loss: 0.1299\n",
      "Epoch 240/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.1557\n",
      "Epoch 241/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.1458\n",
      "Epoch 242/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.1598\n",
      "Epoch 243/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.1462\n",
      "Epoch 244/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.1566\n",
      "Epoch 245/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.1466\n",
      "Epoch 246/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.1450\n",
      "Epoch 247/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.1553\n",
      "Epoch 248/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.1519\n",
      "Epoch 249/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.1480\n",
      "Epoch 250/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.1476\n",
      "Epoch 251/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.1579\n",
      "Epoch 252/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1550\n",
      "Epoch 253/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.1589\n",
      "Epoch 254/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.1639\n",
      "Epoch 255/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.1423\n",
      "Epoch 256/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.1665\n",
      "Epoch 257/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.1446\n",
      "Epoch 258/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1529\n",
      "Epoch 259/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.1584\n",
      "Epoch 260/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.1572\n",
      "Epoch 261/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.1628\n",
      "Epoch 262/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.1507\n",
      "Epoch 263/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.1474\n",
      "Epoch 264/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.1573\n",
      "Epoch 265/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.1576\n",
      "Epoch 266/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.1448\n",
      "Epoch 267/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.1596\n",
      "Epoch 268/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.1589\n",
      "Epoch 269/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.1559\n",
      "Epoch 270/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.1599\n",
      "Epoch 271/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1575\n",
      "Epoch 272/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.1638\n",
      "Epoch 273/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1462\n",
      "Epoch 274/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.1530\n",
      "Epoch 275/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1651\n",
      "Epoch 276/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1630\n",
      "Epoch 277/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.1524\n",
      "Epoch 278/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.1630\n",
      "Epoch 279/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.1407\n",
      "Epoch 280/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.1919\n",
      "Epoch 281/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.1415\n",
      "Epoch 282/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.1681\n",
      "Epoch 283/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.1570\n",
      "Epoch 284/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.1573\n",
      "Epoch 285/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.1576\n",
      "Epoch 286/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.1509\n",
      "Epoch 287/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1608\n",
      "Epoch 288/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1644\n",
      "Epoch 289/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.1587\n",
      "Epoch 290/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.1648\n",
      "Epoch 291/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1617\n",
      "Epoch 292/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1615\n",
      "Epoch 293/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.1628\n",
      "Epoch 294/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.1613\n",
      "Epoch 295/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.1523\n",
      "Epoch 296/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.1600\n",
      "Epoch 297/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1564\n",
      "Epoch 298/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1677\n",
      "Epoch 299/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1628\n",
      "Epoch 300/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.1690\n",
      "Epoch 301/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.1530\n",
      "Epoch 302/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.1697\n",
      "Epoch 303/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1622\n",
      "Epoch 304/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1657\n",
      "Epoch 305/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1592\n",
      "Epoch 306/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.1787\n",
      "Epoch 307/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.1768\n",
      "Epoch 308/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.1766\n",
      "Epoch 309/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1571\n",
      "Epoch 310/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1849\n",
      "Epoch 311/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.1611\n",
      "Epoch 312/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.1699\n",
      "Epoch 313/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1787\n",
      "Epoch 314/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1649\n",
      "Epoch 315/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.1852\n",
      "Epoch 316/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1589\n",
      "Epoch 317/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.1868\n",
      "Epoch 318/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.1799\n",
      "Epoch 319/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.1644\n",
      "Epoch 320/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.1843\n",
      "Epoch 321/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.1640\n",
      "Epoch 322/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.1581\n",
      "Epoch 323/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.1755\n",
      "Epoch 324/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1789\n",
      "Epoch 325/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.1690\n",
      "Epoch 326/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.1699\n",
      "Epoch 327/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.2032\n",
      "Epoch 328/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.1574\n",
      "Epoch 329/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.1966\n",
      "Epoch 330/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1550\n",
      "Epoch 331/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.2106\n",
      "Epoch 332/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1534\n",
      "Epoch 333/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.2031\n",
      "Epoch 334/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1533\n",
      "Epoch 335/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.1918\n",
      "Epoch 336/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1608\n",
      "Epoch 337/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.1756\n",
      "Epoch 338/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.1780\n",
      "Epoch 339/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.1697\n",
      "Epoch 340/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1735\n",
      "Epoch 341/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1763\n",
      "Epoch 342/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.1993\n",
      "Epoch 343/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1787\n",
      "Epoch 344/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.1870\n",
      "Epoch 345/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.1848\n",
      "Epoch 346/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.1983\n",
      "Epoch 347/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.1590\n",
      "Epoch 348/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.1749\n",
      "Epoch 349/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.2096\n",
      "Epoch 350/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.1696\n",
      "Epoch 351/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.1903\n",
      "Epoch 352/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1679\n",
      "Epoch 353/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1758\n",
      "Epoch 354/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.1712\n",
      "Epoch 355/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.1981\n",
      "Epoch 356/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.1712\n",
      "Epoch 357/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.1818\n",
      "Epoch 358/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.1709\n",
      "Epoch 359/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1874\n",
      "Epoch 360/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.1747\n",
      "Epoch 361/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.1910\n",
      "Epoch 362/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.2049\n",
      "Epoch 363/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.1878\n",
      "Epoch 364/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.1821\n",
      "Epoch 365/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.1804\n",
      "Epoch 366/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.1931\n",
      "Epoch 367/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.1725\n",
      "Epoch 368/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.2292\n",
      "Epoch 369/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.1843\n",
      "Epoch 370/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.1930\n",
      "Epoch 371/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.1912\n",
      "Epoch 372/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1703\n",
      "Epoch 373/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.1874\n",
      "Epoch 374/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.1966\n",
      "Epoch 375/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.1809\n",
      "Epoch 376/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.2125\n",
      "Epoch 377/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.1893\n",
      "Epoch 378/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.1876\n",
      "Epoch 379/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.1929\n",
      "Epoch 380/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.1854\n",
      "Epoch 381/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.2108\n",
      "Epoch 382/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.1812\n",
      "Epoch 383/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.2075\n",
      "Epoch 384/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.1894\n",
      "Epoch 385/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.1906\n",
      "Epoch 386/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.2145\n",
      "Epoch 387/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.1815\n",
      "Epoch 388/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.1955\n",
      "Epoch 389/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.2069\n",
      "Epoch 390/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.1966\n",
      "Epoch 391/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.1711\n",
      "Epoch 392/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.2280\n",
      "Epoch 393/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.1937\n",
      "Epoch 394/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.2295\n",
      "Epoch 395/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.1685\n",
      "Epoch 396/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.2343\n",
      "Epoch 397/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.1842\n",
      "Epoch 398/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.2160\n",
      "Epoch 399/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.1751\n",
      "Epoch 400/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.017 - 0s 4ms/step - loss: 0.0074 - val_loss: 0.2058\n",
      "Epoch 401/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.1816\n",
      "Epoch 402/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.1969\n",
      "Epoch 403/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.1999\n",
      "Epoch 404/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.1817\n",
      "Epoch 405/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.2268\n",
      "Epoch 406/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.1823\n",
      "Epoch 407/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.2277\n",
      "Epoch 408/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.2290\n",
      "Epoch 409/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.1876\n",
      "Epoch 410/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.2216\n",
      "Epoch 411/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.2095\n",
      "Epoch 412/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.2070\n",
      "Epoch 413/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.1968\n",
      "Epoch 414/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.2144\n",
      "Epoch 415/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.1947\n",
      "Epoch 416/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.2210\n",
      "Epoch 417/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.2100\n",
      "Epoch 418/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.1939\n",
      "Epoch 419/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.1985\n",
      "Epoch 420/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.1907\n",
      "Epoch 421/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.2687\n",
      "Epoch 422/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.1952\n",
      "Epoch 423/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.2165\n",
      "Epoch 424/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.2138\n",
      "Epoch 425/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.2024\n",
      "Epoch 426/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.2365\n",
      "Epoch 427/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.2012\n",
      "Epoch 428/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.2390\n",
      "Epoch 429/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.1914\n",
      "Epoch 430/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.2538\n",
      "Epoch 431/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.1880\n",
      "Epoch 432/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.2285\n",
      "Epoch 433/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.2152\n",
      "Epoch 434/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.2105\n",
      "Epoch 435/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.2039\n",
      "Epoch 436/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.2303\n",
      "Epoch 437/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.2070\n",
      "Epoch 438/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.2159\n",
      "Epoch 439/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.1969\n",
      "Epoch 440/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.2100\n",
      "Epoch 441/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.2121\n",
      "Epoch 442/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.2150\n",
      "Epoch 443/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.2143\n",
      "Epoch 444/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.2039\n",
      "Epoch 445/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.2275\n",
      "Epoch 446/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.1998\n",
      "Epoch 447/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.2381\n",
      "Epoch 448/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.2092\n",
      "Epoch 449/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.2288\n",
      "Epoch 450/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.2132\n",
      "Epoch 451/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.2150\n",
      "Epoch 452/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.2508\n",
      "Epoch 453/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.2237\n",
      "Epoch 454/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.2290\n",
      "Epoch 455/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.2262\n",
      "Epoch 456/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.2869\n",
      "Epoch 457/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.2220\n",
      "Epoch 458/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.2371\n",
      "Epoch 459/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.2309\n",
      "Epoch 460/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.2273\n",
      "Epoch 461/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.2292\n",
      "Epoch 462/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.2462\n",
      "Epoch 463/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.2254\n",
      "Epoch 464/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.2477\n",
      "Epoch 465/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.2173\n",
      "Epoch 466/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.2590\n",
      "Epoch 467/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.2150\n",
      "Epoch 468/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.2822\n",
      "Epoch 469/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.1996\n",
      "Epoch 470/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.2377\n",
      "Epoch 471/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.2372\n",
      "Epoch 472/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.2316\n",
      "Epoch 473/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.2494\n",
      "Epoch 474/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.2184\n",
      "Epoch 475/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.2793\n",
      "Epoch 476/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.2212\n",
      "Epoch 477/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.2417\n",
      "Epoch 478/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.2209\n",
      "Epoch 479/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.2405\n",
      "Epoch 480/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.2301\n",
      "Epoch 481/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.2316\n",
      "Epoch 482/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.2208\n",
      "Epoch 483/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.2946\n",
      "Epoch 484/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.2241\n",
      "Epoch 485/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.2299\n",
      "Epoch 486/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.2277\n",
      "Epoch 487/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.2411\n",
      "Epoch 488/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.2280\n",
      "Epoch 489/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2362\n",
      "Epoch 490/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.2436\n",
      "Epoch 491/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.2346\n",
      "Epoch 492/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.2398\n",
      "Epoch 493/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.2322\n",
      "Epoch 494/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.2376\n",
      "Epoch 495/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.2372\n",
      "Epoch 496/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.2366\n",
      "Epoch 497/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.2428\n",
      "Epoch 498/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.2442\n",
      "Epoch 499/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.2391\n",
      "Epoch 500/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2416\n",
      "Epoch 501/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.2375\n",
      "Epoch 502/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.2420\n",
      "Epoch 503/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.2452\n",
      "Epoch 504/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.2333\n",
      "Epoch 505/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.2479\n",
      "Epoch 506/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.2551\n",
      "Epoch 507/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.2374\n",
      "Epoch 508/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.2610\n",
      "Epoch 509/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.2352\n",
      "Epoch 510/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.2565\n",
      "Epoch 511/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.2435\n",
      "Epoch 512/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.2539\n",
      "Epoch 513/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.2449\n",
      "Epoch 514/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.2514\n",
      "Epoch 515/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.2381\n",
      "Epoch 516/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.2695\n",
      "Epoch 517/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.2335\n",
      "Epoch 518/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.2463\n",
      "Epoch 519/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.2379\n",
      "Epoch 520/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.2624\n",
      "Epoch 521/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.2426\n",
      "Epoch 522/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.2406\n",
      "Epoch 523/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.2864\n",
      "Epoch 524/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.2398\n",
      "Epoch 525/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.2710\n",
      "Epoch 526/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.2501\n",
      "Epoch 527/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2670\n",
      "Epoch 528/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.2573\n",
      "Epoch 529/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.2630\n",
      "Epoch 530/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.2551\n",
      "Epoch 531/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.2661\n",
      "Epoch 532/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.2587\n",
      "Epoch 533/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.2638\n",
      "Epoch 534/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.2471\n",
      "Epoch 535/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.2763\n",
      "Epoch 536/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.2650\n",
      "Epoch 537/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2520\n",
      "Epoch 538/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.2852\n",
      "Epoch 539/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.2436\n",
      "Epoch 540/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.2772\n",
      "Epoch 541/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.2669\n",
      "Epoch 542/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2712\n",
      "Epoch 543/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.2633\n",
      "Epoch 544/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.2721\n",
      "Epoch 545/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.2602\n",
      "Epoch 546/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.2847\n",
      "Epoch 547/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.2571\n",
      "Epoch 548/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.2724\n",
      "Epoch 549/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.2702\n",
      "Epoch 550/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.2692\n",
      "Epoch 551/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.2745\n",
      "Epoch 552/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2578\n",
      "Epoch 553/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.2776\n",
      "Epoch 554/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.2746\n",
      "Epoch 555/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.2648\n",
      "Epoch 556/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.3035\n",
      "Epoch 557/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.2646\n",
      "Epoch 558/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.2919\n",
      "Epoch 559/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2768\n",
      "Epoch 560/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.2820\n",
      "Epoch 561/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.2664\n",
      "Epoch 562/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.3005\n",
      "Epoch 563/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.2790\n",
      "Epoch 564/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.2894\n",
      "Epoch 565/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.2884\n",
      "Epoch 566/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.2788\n",
      "Epoch 567/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.2828\n",
      "Epoch 568/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.2869\n",
      "Epoch 569/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.2852\n",
      "Epoch 570/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.2960\n",
      "Epoch 571/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.2824\n",
      "Epoch 572/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.2900\n",
      "Epoch 573/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.2879\n",
      "Epoch 574/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.2889\n",
      "Epoch 575/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.2905\n",
      "Epoch 576/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.2866\n",
      "Epoch 577/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.2931\n",
      "Epoch 578/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.2778\n",
      "Epoch 579/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2940\n",
      "Epoch 580/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.2875\n",
      "Epoch 581/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2826\n",
      "Epoch 582/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.2893\n",
      "Epoch 583/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2915\n",
      "Epoch 584/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.2962\n",
      "Epoch 585/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.2842\n",
      "Epoch 586/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.2906\n",
      "Epoch 587/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.2916\n",
      "Epoch 588/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.2953\n",
      "Epoch 589/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.2910\n",
      "Epoch 590/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2986\n",
      "Epoch 591/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 9.9123e-04 - val_loss: 0.2890\n",
      "Epoch 592/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.2816\n",
      "Epoch 593/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.2992\n",
      "Epoch 594/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.2945\n",
      "Epoch 595/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.2997\n",
      "Epoch 596/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.3052\n",
      "Epoch 597/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.2940\n",
      "Epoch 598/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.2988\n",
      "Epoch 599/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.2989\n",
      "Epoch 600/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.2889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bd7848f880>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:06:51.449408Z",
     "start_time": "2021-06-03T11:06:51.253755Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6671862006187439,\n",
       "  0.6358804702758789,\n",
       "  0.6008090376853943,\n",
       "  0.555564820766449,\n",
       "  0.5020275712013245,\n",
       "  0.4416225254535675,\n",
       "  0.38660505414009094,\n",
       "  0.34175804257392883,\n",
       "  0.30675002932548523,\n",
       "  0.2788747251033783,\n",
       "  0.25345027446746826,\n",
       "  0.233786478638649,\n",
       "  0.2187846153974533,\n",
       "  0.2062046378850937,\n",
       "  0.19280290603637695,\n",
       "  0.18329378962516785,\n",
       "  0.17890936136245728,\n",
       "  0.1688135862350464,\n",
       "  0.16004444658756256,\n",
       "  0.15011298656463623,\n",
       "  0.14433372020721436,\n",
       "  0.13483387231826782,\n",
       "  0.1313442587852478,\n",
       "  0.12554848194122314,\n",
       "  0.11928161978721619,\n",
       "  0.11477465182542801,\n",
       "  0.11206276714801788,\n",
       "  0.10710958391427994,\n",
       "  0.10448254644870758,\n",
       "  0.09938198328018188,\n",
       "  0.09726540744304657,\n",
       "  0.09346865117549896,\n",
       "  0.08908681571483612,\n",
       "  0.08684930950403214,\n",
       "  0.08466547727584839,\n",
       "  0.08243473619222641,\n",
       "  0.08059471100568771,\n",
       "  0.07853446155786514,\n",
       "  0.07813920080661774,\n",
       "  0.07512266933917999,\n",
       "  0.07334496825933456,\n",
       "  0.07244572043418884,\n",
       "  0.07119132578372955,\n",
       "  0.07133399695158005,\n",
       "  0.07022207975387573,\n",
       "  0.06805615872144699,\n",
       "  0.06763318926095963,\n",
       "  0.06648125499486923,\n",
       "  0.06507961452007294,\n",
       "  0.06616491824388504,\n",
       "  0.06390736252069473,\n",
       "  0.06280824542045593,\n",
       "  0.062082160264253616,\n",
       "  0.06127353757619858,\n",
       "  0.06099940836429596,\n",
       "  0.05960443988442421,\n",
       "  0.05886616185307503,\n",
       "  0.058953773230314255,\n",
       "  0.05921300873160362,\n",
       "  0.05890554189682007,\n",
       "  0.05865752696990967,\n",
       "  0.05787752568721771,\n",
       "  0.05762488767504692,\n",
       "  0.0620034821331501,\n",
       "  0.05776546895503998,\n",
       "  0.05484933778643608,\n",
       "  0.06147931143641472,\n",
       "  0.0590718649327755,\n",
       "  0.05724763125181198,\n",
       "  0.05328451842069626,\n",
       "  0.05358608812093735,\n",
       "  0.0526709258556366,\n",
       "  0.05568031594157219,\n",
       "  0.05149800702929497,\n",
       "  0.05305829644203186,\n",
       "  0.05738753825426102,\n",
       "  0.0554889477789402,\n",
       "  0.0538521483540535,\n",
       "  0.0556313656270504,\n",
       "  0.05064624547958374,\n",
       "  0.05045779049396515,\n",
       "  0.049664247781038284,\n",
       "  0.04939817264676094,\n",
       "  0.049241773784160614,\n",
       "  0.04949371516704559,\n",
       "  0.049190327525138855,\n",
       "  0.0512484572827816,\n",
       "  0.04814472049474716,\n",
       "  0.04667479172348976,\n",
       "  0.0468423031270504,\n",
       "  0.047559142112731934,\n",
       "  0.047232735902071,\n",
       "  0.04765518754720688,\n",
       "  0.04584923014044762,\n",
       "  0.04576333984732628,\n",
       "  0.04566778242588043,\n",
       "  0.044744882732629776,\n",
       "  0.04698210209608078,\n",
       "  0.044380322098731995,\n",
       "  0.04379909858107567,\n",
       "  0.044984735548496246,\n",
       "  0.044783517718315125,\n",
       "  0.043963588774204254,\n",
       "  0.04312893748283386,\n",
       "  0.04377298057079315,\n",
       "  0.04356472194194794,\n",
       "  0.043856002390384674,\n",
       "  0.04933525621891022,\n",
       "  0.04163047671318054,\n",
       "  0.04573311656713486,\n",
       "  0.04524170607328415,\n",
       "  0.0440102256834507,\n",
       "  0.04038462042808533,\n",
       "  0.04240760952234268,\n",
       "  0.04126683622598648,\n",
       "  0.040920648723840714,\n",
       "  0.041875507682561874,\n",
       "  0.04022372514009476,\n",
       "  0.04324003681540489,\n",
       "  0.04156021401286125,\n",
       "  0.039319127798080444,\n",
       "  0.04065965488553047,\n",
       "  0.04420710355043411,\n",
       "  0.040267787873744965,\n",
       "  0.049794502556324005,\n",
       "  0.04437069967389107,\n",
       "  0.04123014956712723,\n",
       "  0.03964785113930702,\n",
       "  0.03859857842326164,\n",
       "  0.037303198128938675,\n",
       "  0.03603159263730049,\n",
       "  0.03771800547838211,\n",
       "  0.035976771265268326,\n",
       "  0.03602701798081398,\n",
       "  0.036473408341407776,\n",
       "  0.03493626415729523,\n",
       "  0.03629932180047035,\n",
       "  0.035327814519405365,\n",
       "  0.038603074848651886,\n",
       "  0.03624088317155838,\n",
       "  0.03434421122074127,\n",
       "  0.034617431461811066,\n",
       "  0.03357592597603798,\n",
       "  0.03481700271368027,\n",
       "  0.03453131765127182,\n",
       "  0.0347306989133358,\n",
       "  0.04056893661618233,\n",
       "  0.03865209221839905,\n",
       "  0.03264298290014267,\n",
       "  0.03274998068809509,\n",
       "  0.03535112366080284,\n",
       "  0.031600870192050934,\n",
       "  0.03402021899819374,\n",
       "  0.04033465310931206,\n",
       "  0.03203804790973663,\n",
       "  0.031251128762960434,\n",
       "  0.0301887895911932,\n",
       "  0.03153228759765625,\n",
       "  0.03087589703500271,\n",
       "  0.0328797921538353,\n",
       "  0.0324617475271225,\n",
       "  0.03310834988951683,\n",
       "  0.03024839051067829,\n",
       "  0.030377576127648354,\n",
       "  0.029424943029880524,\n",
       "  0.03212853893637657,\n",
       "  0.03137622028589249,\n",
       "  0.03000033274292946,\n",
       "  0.02861541137099266,\n",
       "  0.02872779779136181,\n",
       "  0.028349177911877632,\n",
       "  0.028395043686032295,\n",
       "  0.027756769210100174,\n",
       "  0.029182059690356255,\n",
       "  0.028994331136345863,\n",
       "  0.02713971957564354,\n",
       "  0.027890916913747787,\n",
       "  0.02684701792895794,\n",
       "  0.02715965546667576,\n",
       "  0.026551200076937675,\n",
       "  0.02771381288766861,\n",
       "  0.028688954189419746,\n",
       "  0.02806583233177662,\n",
       "  0.026591965928673744,\n",
       "  0.02794482931494713,\n",
       "  0.027992593124508858,\n",
       "  0.026997476816177368,\n",
       "  0.025859780609607697,\n",
       "  0.031209206208586693,\n",
       "  0.025229988619685173,\n",
       "  0.025515113025903702,\n",
       "  0.024358930066227913,\n",
       "  0.024911878630518913,\n",
       "  0.024676818400621414,\n",
       "  0.027250735089182854,\n",
       "  0.02526709996163845,\n",
       "  0.02424420788884163,\n",
       "  0.02323012240231037,\n",
       "  0.02348996512591839,\n",
       "  0.023030661046504974,\n",
       "  0.023715849965810776,\n",
       "  0.02319447137415409,\n",
       "  0.02699689380824566,\n",
       "  0.027796337381005287,\n",
       "  0.02261875569820404,\n",
       "  0.022931933403015137,\n",
       "  0.024034053087234497,\n",
       "  0.022952664643526077,\n",
       "  0.022550856694579124,\n",
       "  0.022523771971464157,\n",
       "  0.022837163880467415,\n",
       "  0.022386908531188965,\n",
       "  0.021878723055124283,\n",
       "  0.0210542194545269,\n",
       "  0.02161540649831295,\n",
       "  0.021160487085580826,\n",
       "  0.021572094410657883,\n",
       "  0.020540060475468636,\n",
       "  0.020730318501591682,\n",
       "  0.023155178874731064,\n",
       "  0.02127876691520214,\n",
       "  0.0220129806548357,\n",
       "  0.025658154860138893,\n",
       "  0.03426790237426758,\n",
       "  0.024289898574352264,\n",
       "  0.026838690042495728,\n",
       "  0.019297000020742416,\n",
       "  0.02027919888496399,\n",
       "  0.020028067752718925,\n",
       "  0.019160248339176178,\n",
       "  0.018951982259750366,\n",
       "  0.018666110932826996,\n",
       "  0.01859847642481327,\n",
       "  0.018021684139966965,\n",
       "  0.017889251932501793,\n",
       "  0.018814217299222946,\n",
       "  0.018421098589897156,\n",
       "  0.021619083359837532,\n",
       "  0.026202671229839325,\n",
       "  0.01870226301252842,\n",
       "  0.02071652002632618,\n",
       "  0.018335388973355293,\n",
       "  0.01789170689880848,\n",
       "  0.01671447791159153,\n",
       "  0.01725855842232704,\n",
       "  0.01894383504986763,\n",
       "  0.017875956371426582,\n",
       "  0.017522569745779037,\n",
       "  0.01678767427802086,\n",
       "  0.017278920859098434,\n",
       "  0.016253629699349403,\n",
       "  0.016765370965003967,\n",
       "  0.016359297558665276,\n",
       "  0.016564542427659035,\n",
       "  0.01740768365561962,\n",
       "  0.0162443108856678,\n",
       "  0.015400493517518044,\n",
       "  0.018043650314211845,\n",
       "  0.01946074515581131,\n",
       "  0.016902275383472443,\n",
       "  0.017173992469906807,\n",
       "  0.016142988577485085,\n",
       "  0.01518309023231268,\n",
       "  0.015041088685393333,\n",
       "  0.015211854130029678,\n",
       "  0.015946941450238228,\n",
       "  0.015194731764495373,\n",
       "  0.015234113670885563,\n",
       "  0.015254059806466103,\n",
       "  0.01579040102660656,\n",
       "  0.014565167017281055,\n",
       "  0.014589810743927956,\n",
       "  0.01560811884701252,\n",
       "  0.014772112481296062,\n",
       "  0.013920639641582966,\n",
       "  0.015474293380975723,\n",
       "  0.014769189991056919,\n",
       "  0.015816450119018555,\n",
       "  0.018496543169021606,\n",
       "  0.0172613263130188,\n",
       "  0.01778551936149597,\n",
       "  0.013119914568960667,\n",
       "  0.01441606879234314,\n",
       "  0.014605131931602955,\n",
       "  0.013332352042198181,\n",
       "  0.013156071305274963,\n",
       "  0.013567621819674969,\n",
       "  0.012937964871525764,\n",
       "  0.012544794008135796,\n",
       "  0.01234167255461216,\n",
       "  0.012917892076075077,\n",
       "  0.013110866770148277,\n",
       "  0.012922718189656734,\n",
       "  0.01220586709678173,\n",
       "  0.01305613573640585,\n",
       "  0.012644805945456028,\n",
       "  0.013299503363668919,\n",
       "  0.011892922222614288,\n",
       "  0.011593048460781574,\n",
       "  0.01159275509417057,\n",
       "  0.014729512855410576,\n",
       "  0.013426373712718487,\n",
       "  0.012034234590828419,\n",
       "  0.01203525997698307,\n",
       "  0.011376720853149891,\n",
       "  0.01187125500291586,\n",
       "  0.011607024818658829,\n",
       "  0.011753483675420284,\n",
       "  0.011318904347717762,\n",
       "  0.01119908969849348,\n",
       "  0.011611494235694408,\n",
       "  0.011422114446759224,\n",
       "  0.010965107008814812,\n",
       "  0.011433375999331474,\n",
       "  0.010765928775072098,\n",
       "  0.011278809979557991,\n",
       "  0.011718426831066608,\n",
       "  0.01250850223004818,\n",
       "  0.01031261496245861,\n",
       "  0.015167029574513435,\n",
       "  0.01033916138112545,\n",
       "  0.01331536564975977,\n",
       "  0.010548118501901627,\n",
       "  0.01085339393466711,\n",
       "  0.010022364556789398,\n",
       "  0.01107744313776493,\n",
       "  0.013353568501770496,\n",
       "  0.010283288545906544,\n",
       "  0.012557674199342728,\n",
       "  0.010680371895432472,\n",
       "  0.013413999229669571,\n",
       "  0.012287711724638939,\n",
       "  0.010688969865441322,\n",
       "  0.012948734685778618,\n",
       "  0.010231822729110718,\n",
       "  0.012449349276721478,\n",
       "  0.009443327784538269,\n",
       "  0.012863468378782272,\n",
       "  0.009981782175600529,\n",
       "  0.009542726911604404,\n",
       "  0.009693240746855736,\n",
       "  0.009731189347803593,\n",
       "  0.00970515701919794,\n",
       "  0.01001858152449131,\n",
       "  0.010271643288433552,\n",
       "  0.010551323182880878,\n",
       "  0.012927410192787647,\n",
       "  0.01072498969733715,\n",
       "  0.010834043845534325,\n",
       "  0.00891802553087473,\n",
       "  0.009771899320185184,\n",
       "  0.010288775898516178,\n",
       "  0.008736396208405495,\n",
       "  0.00960975605994463,\n",
       "  0.008732925169169903,\n",
       "  0.009244170971214771,\n",
       "  0.008196921087801456,\n",
       "  0.009255637414753437,\n",
       "  0.007987883873283863,\n",
       "  0.00797488447278738,\n",
       "  0.008104422129690647,\n",
       "  0.008514807559549809,\n",
       "  0.008059724234044552,\n",
       "  0.008520700968801975,\n",
       "  0.008584504947066307,\n",
       "  0.00822286307811737,\n",
       "  0.008275038562715054,\n",
       "  0.009088165126740932,\n",
       "  0.011463137343525887,\n",
       "  0.007554949261248112,\n",
       "  0.007722458336502314,\n",
       "  0.007314889691770077,\n",
       "  0.008586151525378227,\n",
       "  0.007731221616268158,\n",
       "  0.007335756905376911,\n",
       "  0.00881639588624239,\n",
       "  0.007470868062227964,\n",
       "  0.006935521494597197,\n",
       "  0.006801622919738293,\n",
       "  0.007044890895485878,\n",
       "  0.00710503663867712,\n",
       "  0.007280320860445499,\n",
       "  0.0075745354406535625,\n",
       "  0.0067616901360452175,\n",
       "  0.006675138603895903,\n",
       "  0.0069016157649457455,\n",
       "  0.007696403656154871,\n",
       "  0.007332291454076767,\n",
       "  0.007614822126924992,\n",
       "  0.007590179797261953,\n",
       "  0.008623589761555195,\n",
       "  0.009336644783616066,\n",
       "  0.007303817663341761,\n",
       "  0.007875463925302029,\n",
       "  0.008308296091854572,\n",
       "  0.007634834852069616,\n",
       "  0.006905962247401476,\n",
       "  0.0061286017298698425,\n",
       "  0.006274400744587183,\n",
       "  0.006812465377151966,\n",
       "  0.006807804573327303,\n",
       "  0.006631467491388321,\n",
       "  0.005810363218188286,\n",
       "  0.006917842663824558,\n",
       "  0.007202353794127703,\n",
       "  0.0064780511893332005,\n",
       "  0.006399526260793209,\n",
       "  0.0071692029014229774,\n",
       "  0.006302178837358952,\n",
       "  0.006349482107907534,\n",
       "  0.006197422742843628,\n",
       "  0.005386387929320335,\n",
       "  0.0052491528913378716,\n",
       "  0.0056146360002458096,\n",
       "  0.005947915371507406,\n",
       "  0.005205415189266205,\n",
       "  0.005565136205404997,\n",
       "  0.005240493919700384,\n",
       "  0.005497780628502369,\n",
       "  0.006373564247041941,\n",
       "  0.0066148145124316216,\n",
       "  0.007051325403153896,\n",
       "  0.005278604105114937,\n",
       "  0.00610901927575469,\n",
       "  0.005870696622878313,\n",
       "  0.005671387538313866,\n",
       "  0.005229845643043518,\n",
       "  0.006266607437282801,\n",
       "  0.005765076726675034,\n",
       "  0.006339820567518473,\n",
       "  0.0062364027835428715,\n",
       "  0.01014154963195324,\n",
       "  0.0062377131544053555,\n",
       "  0.004677241202443838,\n",
       "  0.0050939274951815605,\n",
       "  0.004444225691258907,\n",
       "  0.004748101346194744,\n",
       "  0.0052555319853127,\n",
       "  0.004409761633723974,\n",
       "  0.005128351040184498,\n",
       "  0.004326873924583197,\n",
       "  0.004175196401774883,\n",
       "  0.004150932654738426,\n",
       "  0.00457758828997612,\n",
       "  0.004553989972919226,\n",
       "  0.004078997299075127,\n",
       "  0.0051294490694999695,\n",
       "  0.004178821574896574,\n",
       "  0.004305749200284481,\n",
       "  0.004463293123990297,\n",
       "  0.004987414926290512,\n",
       "  0.005049251019954681,\n",
       "  0.0057324632070958614,\n",
       "  0.003957671113312244,\n",
       "  0.004162465687841177,\n",
       "  0.007534882985055447,\n",
       "  0.00612181331962347,\n",
       "  0.004778796341270208,\n",
       "  0.004073313437402248,\n",
       "  0.004006270319223404,\n",
       "  0.003998268395662308,\n",
       "  0.004876183345913887,\n",
       "  0.004833097103983164,\n",
       "  0.004175531677901745,\n",
       "  0.004295263905078173,\n",
       "  0.004645423032343388,\n",
       "  0.003551641246303916,\n",
       "  0.004616994876414537,\n",
       "  0.0073565272614359856,\n",
       "  0.003593645989894867,\n",
       "  0.004191860556602478,\n",
       "  0.0036014565266668797,\n",
       "  0.003924438264220953,\n",
       "  0.0035409305710345507,\n",
       "  0.00435047410428524,\n",
       "  0.00397372804582119,\n",
       "  0.00423383479937911,\n",
       "  0.0031642126850783825,\n",
       "  0.003569899359717965,\n",
       "  0.0035844752565026283,\n",
       "  0.0034487908706068993,\n",
       "  0.00559619115665555,\n",
       "  0.006686560809612274,\n",
       "  0.005987242329865694,\n",
       "  0.0037493964191526175,\n",
       "  0.003393786959350109,\n",
       "  0.0034277623053640127,\n",
       "  0.0030981791205704212,\n",
       "  0.003137090476229787,\n",
       "  0.0032321251928806305,\n",
       "  0.0030734881293028593,\n",
       "  0.002872076351195574,\n",
       "  0.0032110160682350397,\n",
       "  0.003131924895569682,\n",
       "  0.0028779171407222748,\n",
       "  0.002900256309658289,\n",
       "  0.0028438428416848183,\n",
       "  0.0028694516513496637,\n",
       "  0.0027780821546912193,\n",
       "  0.002787783043459058,\n",
       "  0.002621927997097373,\n",
       "  0.0026848039124161005,\n",
       "  0.002962098689749837,\n",
       "  0.0024604657664895058,\n",
       "  0.0033243619836866856,\n",
       "  0.003422098234295845,\n",
       "  0.0027483843732625246,\n",
       "  0.0029329985845834017,\n",
       "  0.00302904867567122,\n",
       "  0.0038961204700171947,\n",
       "  0.002916308119893074,\n",
       "  0.002556117018684745,\n",
       "  0.002654577372595668,\n",
       "  0.0024266871623694897,\n",
       "  0.0028721909038722515,\n",
       "  0.003426637966185808,\n",
       "  0.002126511186361313,\n",
       "  0.003246185602620244,\n",
       "  0.002433382673189044,\n",
       "  0.002964969724416733,\n",
       "  0.002680762205272913,\n",
       "  0.003346481826156378,\n",
       "  0.0031787657644599676,\n",
       "  0.003944519907236099,\n",
       "  0.0028943943325430155,\n",
       "  0.002464140299707651,\n",
       "  0.002529272809624672,\n",
       "  0.002437000861391425,\n",
       "  0.002347247675061226,\n",
       "  0.002341758692637086,\n",
       "  0.0021738086361438036,\n",
       "  0.0021296164486557245,\n",
       "  0.0024059286806732416,\n",
       "  0.003030400024726987,\n",
       "  0.0027042063884437084,\n",
       "  0.002253419952467084,\n",
       "  0.0033218013122677803,\n",
       "  0.0030282342340797186,\n",
       "  0.0028176417108625174,\n",
       "  0.002464772667735815,\n",
       "  0.0021033992525190115,\n",
       "  0.001957900822162628,\n",
       "  0.001930411672219634,\n",
       "  0.0019423168851062655,\n",
       "  0.0020965146832168102,\n",
       "  0.002275401260703802,\n",
       "  0.0019269522745162249,\n",
       "  0.0018486124463379383,\n",
       "  0.0018546013161540031,\n",
       "  0.001815565163269639,\n",
       "  0.0017927862936630845,\n",
       "  0.0025616546627134085,\n",
       "  0.002960521960631013,\n",
       "  0.002746512182056904,\n",
       "  0.0027615444269031286,\n",
       "  0.0023180434945970774,\n",
       "  0.002032635034993291,\n",
       "  0.00220917584374547,\n",
       "  0.0016671220073476434,\n",
       "  0.0019170107552781701,\n",
       "  0.0023522544652223587,\n",
       "  0.002112680347636342,\n",
       "  0.0019081553909927607,\n",
       "  0.0016001634066924453,\n",
       "  0.001675400068052113,\n",
       "  0.0017103288555517793,\n",
       "  0.001700139488093555,\n",
       "  0.001765655935741961,\n",
       "  0.0016553268069401383,\n",
       "  0.0016107570845633745,\n",
       "  0.0014758058823645115,\n",
       "  0.0017598813865333796,\n",
       "  0.0015123824123293161,\n",
       "  0.00147982535418123,\n",
       "  0.0014596270630136132,\n",
       "  0.0014691489050164819,\n",
       "  0.0014590813079848886,\n",
       "  0.0015180304180830717,\n",
       "  0.0014983857981860638,\n",
       "  0.0014300879556685686,\n",
       "  0.0014203018508851528,\n",
       "  0.0014067189767956734,\n",
       "  0.0014214563416317105,\n",
       "  0.0013576220953837037,\n",
       "  0.0014277133159339428,\n",
       "  0.0014286303194239736,\n",
       "  0.0013693938963115215,\n",
       "  0.0013675699010491371,\n",
       "  0.0013094941386952996,\n",
       "  0.0013140911469236016,\n",
       "  0.0013628462329506874,\n",
       "  0.0013266815803945065,\n",
       "  0.001329065766185522,\n",
       "  0.0014608296332880855,\n",
       "  0.0013922287616878748,\n",
       "  0.0015439351554960012,\n",
       "  0.0013145868433639407,\n",
       "  0.001304058125242591,\n",
       "  0.001245587132871151,\n",
       "  0.0019208886660635471],\n",
       " 'val_loss': [0.6555649638175964,\n",
       "  0.6245044469833374,\n",
       "  0.5843269228935242,\n",
       "  0.5307785868644714,\n",
       "  0.4712394177913666,\n",
       "  0.4086940884590149,\n",
       "  0.3564760386943817,\n",
       "  0.31036287546157837,\n",
       "  0.27974122762680054,\n",
       "  0.24908359348773956,\n",
       "  0.22944380342960358,\n",
       "  0.20870181918144226,\n",
       "  0.1955461949110031,\n",
       "  0.1835532784461975,\n",
       "  0.17485877871513367,\n",
       "  0.16687163710594177,\n",
       "  0.15962767601013184,\n",
       "  0.15436114370822906,\n",
       "  0.14847348630428314,\n",
       "  0.14640416204929352,\n",
       "  0.13746985793113708,\n",
       "  0.1412705034017563,\n",
       "  0.13193993270397186,\n",
       "  0.12929849326610565,\n",
       "  0.1260261833667755,\n",
       "  0.12454354017972946,\n",
       "  0.12558624148368835,\n",
       "  0.11909607797861099,\n",
       "  0.11649378389120102,\n",
       "  0.12135007977485657,\n",
       "  0.11500851064920425,\n",
       "  0.11544624716043472,\n",
       "  0.1155945435166359,\n",
       "  0.11364538222551346,\n",
       "  0.11490678787231445,\n",
       "  0.11372790485620499,\n",
       "  0.11423909664154053,\n",
       "  0.11188246309757233,\n",
       "  0.11130771785974503,\n",
       "  0.11144956946372986,\n",
       "  0.11230558156967163,\n",
       "  0.1123993769288063,\n",
       "  0.10909377783536911,\n",
       "  0.11633189767599106,\n",
       "  0.11140605062246323,\n",
       "  0.11518806219100952,\n",
       "  0.10659220069646835,\n",
       "  0.11633456498384476,\n",
       "  0.10852038115262985,\n",
       "  0.11735904216766357,\n",
       "  0.10937096923589706,\n",
       "  0.11018306016921997,\n",
       "  0.11228208243846893,\n",
       "  0.11007833480834961,\n",
       "  0.11013782769441605,\n",
       "  0.1125066950917244,\n",
       "  0.1117008700966835,\n",
       "  0.11548300832509995,\n",
       "  0.11392441391944885,\n",
       "  0.11513876914978027,\n",
       "  0.10967069864273071,\n",
       "  0.11422409117221832,\n",
       "  0.11223240941762924,\n",
       "  0.11071982979774475,\n",
       "  0.11285775154829025,\n",
       "  0.1131804808974266,\n",
       "  0.10751478374004364,\n",
       "  0.11873923987150192,\n",
       "  0.10909036546945572,\n",
       "  0.12477634847164154,\n",
       "  0.11165054887533188,\n",
       "  0.1201612800359726,\n",
       "  0.11840607225894928,\n",
       "  0.11572540551424026,\n",
       "  0.11422377079725266,\n",
       "  0.11001096665859222,\n",
       "  0.14035390317440033,\n",
       "  0.1092272400856018,\n",
       "  0.11590302735567093,\n",
       "  0.1194472387433052,\n",
       "  0.11306343972682953,\n",
       "  0.11803542822599411,\n",
       "  0.11405657976865768,\n",
       "  0.11727391928434372,\n",
       "  0.1135687530040741,\n",
       "  0.12628135085105896,\n",
       "  0.1154976412653923,\n",
       "  0.12268037348985672,\n",
       "  0.1155175268650055,\n",
       "  0.12131267040967941,\n",
       "  0.11709566414356232,\n",
       "  0.12276281416416168,\n",
       "  0.12322257459163666,\n",
       "  0.1166357547044754,\n",
       "  0.11759843677282333,\n",
       "  0.12217528373003006,\n",
       "  0.12266937643289566,\n",
       "  0.12357811629772186,\n",
       "  0.12206690013408661,\n",
       "  0.12661540508270264,\n",
       "  0.12759530544281006,\n",
       "  0.12074251472949982,\n",
       "  0.1219949796795845,\n",
       "  0.11792337894439697,\n",
       "  0.1291836053133011,\n",
       "  0.1172369197010994,\n",
       "  0.13148626685142517,\n",
       "  0.1189277246594429,\n",
       "  0.1322574019432068,\n",
       "  0.12887687981128693,\n",
       "  0.12266957014799118,\n",
       "  0.13087107241153717,\n",
       "  0.12132808566093445,\n",
       "  0.13006511330604553,\n",
       "  0.12568625807762146,\n",
       "  0.12139293551445007,\n",
       "  0.14019256830215454,\n",
       "  0.12462695688009262,\n",
       "  0.1370415985584259,\n",
       "  0.12234002351760864,\n",
       "  0.12956389784812927,\n",
       "  0.11970268934965134,\n",
       "  0.15256954729557037,\n",
       "  0.12023141235113144,\n",
       "  0.1396903395652771,\n",
       "  0.12188923358917236,\n",
       "  0.13880665600299835,\n",
       "  0.12233938276767731,\n",
       "  0.13036110997200012,\n",
       "  0.12991365790367126,\n",
       "  0.13155435025691986,\n",
       "  0.12540505826473236,\n",
       "  0.1327148824930191,\n",
       "  0.1302044540643692,\n",
       "  0.13179831206798553,\n",
       "  0.1482233852148056,\n",
       "  0.12608346343040466,\n",
       "  0.1318199783563614,\n",
       "  0.12222959846258163,\n",
       "  0.1379805952310562,\n",
       "  0.13259392976760864,\n",
       "  0.13053785264492035,\n",
       "  0.13097406923770905,\n",
       "  0.13459473848342896,\n",
       "  0.13209179043769836,\n",
       "  0.12988606095314026,\n",
       "  0.16182327270507812,\n",
       "  0.12985682487487793,\n",
       "  0.16180981695652008,\n",
       "  0.1231212466955185,\n",
       "  0.14509622752666473,\n",
       "  0.1321292221546173,\n",
       "  0.1509101539850235,\n",
       "  0.1331949383020401,\n",
       "  0.14158305525779724,\n",
       "  0.1381852626800537,\n",
       "  0.139805406332016,\n",
       "  0.14726805686950684,\n",
       "  0.13536344468593597,\n",
       "  0.13753019273281097,\n",
       "  0.14452137053012848,\n",
       "  0.149214968085289,\n",
       "  0.14193683862686157,\n",
       "  0.1411827951669693,\n",
       "  0.14224714040756226,\n",
       "  0.13891904056072235,\n",
       "  0.13649113476276398,\n",
       "  0.14245368540287018,\n",
       "  0.14054366946220398,\n",
       "  0.1365918666124344,\n",
       "  0.14024986326694489,\n",
       "  0.14200420677661896,\n",
       "  0.13671328127384186,\n",
       "  0.14081980288028717,\n",
       "  0.1351700872182846,\n",
       "  0.14585568010807037,\n",
       "  0.14055190980434418,\n",
       "  0.14317992329597473,\n",
       "  0.1505904197692871,\n",
       "  0.13930635154247284,\n",
       "  0.14703364670276642,\n",
       "  0.14090880751609802,\n",
       "  0.143633633852005,\n",
       "  0.1519705206155777,\n",
       "  0.14171148836612701,\n",
       "  0.1406528651714325,\n",
       "  0.14415130019187927,\n",
       "  0.1393066942691803,\n",
       "  0.1469908207654953,\n",
       "  0.13823196291923523,\n",
       "  0.146057590842247,\n",
       "  0.1400410383939743,\n",
       "  0.13842883706092834,\n",
       "  0.141507089138031,\n",
       "  0.14509128034114838,\n",
       "  0.15024320781230927,\n",
       "  0.14889414608478546,\n",
       "  0.14921516180038452,\n",
       "  0.14442497491836548,\n",
       "  0.1428363174200058,\n",
       "  0.14464840292930603,\n",
       "  0.1405920535326004,\n",
       "  0.13380375504493713,\n",
       "  0.15598022937774658,\n",
       "  0.14651094377040863,\n",
       "  0.1490384042263031,\n",
       "  0.15950578451156616,\n",
       "  0.14674431085586548,\n",
       "  0.1625242829322815,\n",
       "  0.1414196789264679,\n",
       "  0.16023223102092743,\n",
       "  0.13756924867630005,\n",
       "  0.15467244386672974,\n",
       "  0.14283877611160278,\n",
       "  0.14887870848178864,\n",
       "  0.15020139515399933,\n",
       "  0.15646760165691376,\n",
       "  0.1454407423734665,\n",
       "  0.14454929530620575,\n",
       "  0.1413443237543106,\n",
       "  0.16370853781700134,\n",
       "  0.1368580460548401,\n",
       "  0.17741605639457703,\n",
       "  0.12773366272449493,\n",
       "  0.16536137461662292,\n",
       "  0.13971634209156036,\n",
       "  0.15643741190433502,\n",
       "  0.14287956058979034,\n",
       "  0.1448858082294464,\n",
       "  0.15115706622600555,\n",
       "  0.13681112229824066,\n",
       "  0.14803388714790344,\n",
       "  0.15174809098243713,\n",
       "  0.14608652889728546,\n",
       "  0.14689898490905762,\n",
       "  0.16035422682762146,\n",
       "  0.14243997633457184,\n",
       "  0.1970282793045044,\n",
       "  0.129924938082695,\n",
       "  0.15569354593753815,\n",
       "  0.1457601636648178,\n",
       "  0.15977412462234497,\n",
       "  0.1461949348449707,\n",
       "  0.156648188829422,\n",
       "  0.14655619859695435,\n",
       "  0.14504174888134003,\n",
       "  0.15525826811790466,\n",
       "  0.1518738716840744,\n",
       "  0.1479552835226059,\n",
       "  0.14756391942501068,\n",
       "  0.15794001519680023,\n",
       "  0.155020073056221,\n",
       "  0.1588575541973114,\n",
       "  0.16388116776943207,\n",
       "  0.1422697901725769,\n",
       "  0.1665421724319458,\n",
       "  0.144605353474617,\n",
       "  0.15294983983039856,\n",
       "  0.1584097445011139,\n",
       "  0.15718860924243927,\n",
       "  0.16278818249702454,\n",
       "  0.15071286261081696,\n",
       "  0.14739884436130524,\n",
       "  0.1572933793067932,\n",
       "  0.15759989619255066,\n",
       "  0.14475449919700623,\n",
       "  0.15955740213394165,\n",
       "  0.1588772088289261,\n",
       "  0.1558687686920166,\n",
       "  0.15990951657295227,\n",
       "  0.15749214589595795,\n",
       "  0.16383928060531616,\n",
       "  0.14616654813289642,\n",
       "  0.15302443504333496,\n",
       "  0.165082648396492,\n",
       "  0.163009911775589,\n",
       "  0.15236246585845947,\n",
       "  0.16298352181911469,\n",
       "  0.1407417505979538,\n",
       "  0.191935196518898,\n",
       "  0.14150889217853546,\n",
       "  0.1680782288312912,\n",
       "  0.15699468553066254,\n",
       "  0.15728186070919037,\n",
       "  0.15756121277809143,\n",
       "  0.1509229689836502,\n",
       "  0.16082069277763367,\n",
       "  0.16443219780921936,\n",
       "  0.1587330549955368,\n",
       "  0.164765864610672,\n",
       "  0.16174905002117157,\n",
       "  0.16154611110687256,\n",
       "  0.16282686591148376,\n",
       "  0.1612965613603592,\n",
       "  0.15227390825748444,\n",
       "  0.16003145277500153,\n",
       "  0.15635395050048828,\n",
       "  0.16770029067993164,\n",
       "  0.16280518472194672,\n",
       "  0.16899123787879944,\n",
       "  0.15299133956432343,\n",
       "  0.16969004273414612,\n",
       "  0.16217514872550964,\n",
       "  0.1657169610261917,\n",
       "  0.15919557213783264,\n",
       "  0.17869193851947784,\n",
       "  0.17678536474704742,\n",
       "  0.176642507314682,\n",
       "  0.15712398290634155,\n",
       "  0.18487152457237244,\n",
       "  0.1610734760761261,\n",
       "  0.16986289620399475,\n",
       "  0.17870083451271057,\n",
       "  0.16487154364585876,\n",
       "  0.1851639598608017,\n",
       "  0.15889102220535278,\n",
       "  0.1868167519569397,\n",
       "  0.179922416806221,\n",
       "  0.16442888975143433,\n",
       "  0.18428121507167816,\n",
       "  0.16398464143276215,\n",
       "  0.15806151926517487,\n",
       "  0.17554648220539093,\n",
       "  0.17894932627677917,\n",
       "  0.168971449136734,\n",
       "  0.16987600922584534,\n",
       "  0.20320510864257812,\n",
       "  0.15743952989578247,\n",
       "  0.19663791358470917,\n",
       "  0.15495020151138306,\n",
       "  0.21063366532325745,\n",
       "  0.15342570841312408,\n",
       "  0.2030908614397049,\n",
       "  0.15334083139896393,\n",
       "  0.191776841878891,\n",
       "  0.16081109642982483,\n",
       "  0.1756020188331604,\n",
       "  0.17798006534576416,\n",
       "  0.16965600848197937,\n",
       "  0.17349770665168762,\n",
       "  0.17630638182163239,\n",
       "  0.19929790496826172,\n",
       "  0.17870672047138214,\n",
       "  0.18695998191833496,\n",
       "  0.18483184278011322,\n",
       "  0.19825389981269836,\n",
       "  0.1590023636817932,\n",
       "  0.17490310966968536,\n",
       "  0.2096269279718399,\n",
       "  0.16964097321033478,\n",
       "  0.1903214007616043,\n",
       "  0.16788101196289062,\n",
       "  0.17584967613220215,\n",
       "  0.1711740642786026,\n",
       "  0.19807465374469757,\n",
       "  0.1711767166852951,\n",
       "  0.18182291090488434,\n",
       "  0.1708572506904602,\n",
       "  0.1874363124370575,\n",
       "  0.17473703622817993,\n",
       "  0.19098301231861115,\n",
       "  0.20491839945316315,\n",
       "  0.18782579898834229,\n",
       "  0.18210215866565704,\n",
       "  0.18037647008895874,\n",
       "  0.1930610090494156,\n",
       "  0.17250339686870575,\n",
       "  0.2292470932006836,\n",
       "  0.1842627227306366,\n",
       "  0.1929815113544464,\n",
       "  0.1911705583333969,\n",
       "  0.17027582228183746,\n",
       "  0.18742328882217407,\n",
       "  0.19656065106391907,\n",
       "  0.18089093267917633,\n",
       "  0.21253158152103424,\n",
       "  0.18933144211769104,\n",
       "  0.18763256072998047,\n",
       "  0.192862868309021,\n",
       "  0.18541878461837769,\n",
       "  0.21084855496883392,\n",
       "  0.18120162189006805,\n",
       "  0.20753107964992523,\n",
       "  0.1893996298313141,\n",
       "  0.19058826565742493,\n",
       "  0.21447880566120148,\n",
       "  0.18153077363967896,\n",
       "  0.19546854496002197,\n",
       "  0.20687603950500488,\n",
       "  0.19660644233226776,\n",
       "  0.17111237347126007,\n",
       "  0.22799861431121826,\n",
       "  0.19368460774421692,\n",
       "  0.22953739762306213,\n",
       "  0.16851040720939636,\n",
       "  0.23434704542160034,\n",
       "  0.1841854751110077,\n",
       "  0.21599730849266052,\n",
       "  0.17513233423233032,\n",
       "  0.20583447813987732,\n",
       "  0.1815778762102127,\n",
       "  0.1969321072101593,\n",
       "  0.19986461102962494,\n",
       "  0.18174245953559875,\n",
       "  0.22683915495872498,\n",
       "  0.18226759135723114,\n",
       "  0.22772493958473206,\n",
       "  0.22902153432369232,\n",
       "  0.18764296174049377,\n",
       "  0.22161999344825745,\n",
       "  0.20949812233448029,\n",
       "  0.2069716453552246,\n",
       "  0.1968466192483902,\n",
       "  0.21437956392765045,\n",
       "  0.19474966824054718,\n",
       "  0.2210305631160736,\n",
       "  0.21000808477401733,\n",
       "  0.1938713639974594,\n",
       "  0.19851720333099365,\n",
       "  0.19070376455783844,\n",
       "  0.26870304346084595,\n",
       "  0.19516605138778687,\n",
       "  0.2165081948041916,\n",
       "  0.2137589156627655,\n",
       "  0.2024046927690506,\n",
       "  0.2364746779203415,\n",
       "  0.2012106329202652,\n",
       "  0.23898109793663025,\n",
       "  0.19135747849941254,\n",
       "  0.2537878751754761,\n",
       "  0.1879761964082718,\n",
       "  0.22854366898536682,\n",
       "  0.2152004837989807,\n",
       "  0.21053479611873627,\n",
       "  0.20386794209480286,\n",
       "  0.23030421137809753,\n",
       "  0.20704972743988037,\n",
       "  0.2158830463886261,\n",
       "  0.1969035416841507,\n",
       "  0.21000392735004425,\n",
       "  0.21209093928337097,\n",
       "  0.2150009721517563,\n",
       "  0.21426475048065186,\n",
       "  0.20386600494384766,\n",
       "  0.22750870883464813,\n",
       "  0.1998077780008316,\n",
       "  0.2380802184343338,\n",
       "  0.20915673673152924,\n",
       "  0.22878500819206238,\n",
       "  0.2132115364074707,\n",
       "  0.2150004655122757,\n",
       "  0.25082874298095703,\n",
       "  0.22368410229682922,\n",
       "  0.22904066741466522,\n",
       "  0.22624878585338593,\n",
       "  0.28685492277145386,\n",
       "  0.22197578847408295,\n",
       "  0.23712384700775146,\n",
       "  0.23088015615940094,\n",
       "  0.22733581066131592,\n",
       "  0.22917954623699188,\n",
       "  0.246164008975029,\n",
       "  0.2254190295934677,\n",
       "  0.24766863882541656,\n",
       "  0.21729180216789246,\n",
       "  0.25895118713378906,\n",
       "  0.21499572694301605,\n",
       "  0.2821761965751648,\n",
       "  0.19959591329097748,\n",
       "  0.23765988647937775,\n",
       "  0.23723356425762177,\n",
       "  0.2316008359193802,\n",
       "  0.2494105100631714,\n",
       "  0.2184140533208847,\n",
       "  0.27934861183166504,\n",
       "  0.22121472656726837,\n",
       "  0.24170397222042084,\n",
       "  0.22092238068580627,\n",
       "  0.24052250385284424,\n",
       "  0.23006759583950043,\n",
       "  0.2315569818019867,\n",
       "  0.22077566385269165,\n",
       "  0.2946295440196991,\n",
       "  0.22407032549381256,\n",
       "  0.22985658049583435,\n",
       "  0.22772963345050812,\n",
       "  0.2411087155342102,\n",
       "  0.2279849499464035,\n",
       "  0.2361854612827301,\n",
       "  0.2435844987630844,\n",
       "  0.23462866246700287,\n",
       "  0.2397608757019043,\n",
       "  0.2322341799736023,\n",
       "  0.2376386970281601,\n",
       "  0.23722700774669647,\n",
       "  0.23656733334064484,\n",
       "  0.242837592959404,\n",
       "  0.2441515028476715,\n",
       "  0.23914344608783722,\n",
       "  0.24160099029541016,\n",
       "  0.2374609261751175,\n",
       "  0.24202173948287964,\n",
       "  0.2452392578125,\n",
       "  0.23331813514232635,\n",
       "  0.2478608936071396,\n",
       "  0.2550813853740692,\n",
       "  0.23737581074237823,\n",
       "  0.261023610830307,\n",
       "  0.23515087366104126,\n",
       "  0.2565155327320099,\n",
       "  0.24354350566864014,\n",
       "  0.25394943356513977,\n",
       "  0.24489523470401764,\n",
       "  0.25144585967063904,\n",
       "  0.23806650936603546,\n",
       "  0.2694847583770752,\n",
       "  0.23352104425430298,\n",
       "  0.2463480830192566,\n",
       "  0.2378501296043396,\n",
       "  0.26239001750946045,\n",
       "  0.2425539493560791,\n",
       "  0.24058343470096588,\n",
       "  0.28644827008247375,\n",
       "  0.23976247012615204,\n",
       "  0.2710176110267639,\n",
       "  0.2500680387020111,\n",
       "  0.26704826951026917,\n",
       "  0.25731801986694336,\n",
       "  0.2629507780075073,\n",
       "  0.2550906538963318,\n",
       "  0.2660805881023407,\n",
       "  0.2587193548679352,\n",
       "  0.26384854316711426,\n",
       "  0.24708104133605957,\n",
       "  0.27627313137054443,\n",
       "  0.265032559633255,\n",
       "  0.2519603669643402,\n",
       "  0.28521156311035156,\n",
       "  0.24360843002796173,\n",
       "  0.2772442698478699,\n",
       "  0.2668739855289459,\n",
       "  0.2711770832538605,\n",
       "  0.2633073329925537,\n",
       "  0.27206042408943176,\n",
       "  0.26017701625823975,\n",
       "  0.28470006585121155,\n",
       "  0.25713875889778137,\n",
       "  0.2724277675151825,\n",
       "  0.2702257037162781,\n",
       "  0.2691817581653595,\n",
       "  0.27447038888931274,\n",
       "  0.2578451335430145,\n",
       "  0.27762630581855774,\n",
       "  0.27463406324386597,\n",
       "  0.2647611200809479,\n",
       "  0.30347633361816406,\n",
       "  0.26455777883529663,\n",
       "  0.2919362485408783,\n",
       "  0.2768411636352539,\n",
       "  0.28200748562812805,\n",
       "  0.26637396216392517,\n",
       "  0.300528347492218,\n",
       "  0.2790190577507019,\n",
       "  0.2894306480884552,\n",
       "  0.28844594955444336,\n",
       "  0.27883976697921753,\n",
       "  0.2828366160392761,\n",
       "  0.2869080603122711,\n",
       "  0.28521767258644104,\n",
       "  0.29598280787467957,\n",
       "  0.28240904211997986,\n",
       "  0.2900223135948181,\n",
       "  0.2878996431827545,\n",
       "  0.2888776659965515,\n",
       "  0.2905457615852356,\n",
       "  0.286556214094162,\n",
       "  0.29306983947753906,\n",
       "  0.27782097458839417,\n",
       "  0.29396483302116394,\n",
       "  0.2875153422355652,\n",
       "  0.2826264202594757,\n",
       "  0.2893330454826355,\n",
       "  0.29146385192871094,\n",
       "  0.2961835265159607,\n",
       "  0.2842187285423279,\n",
       "  0.2906111776828766,\n",
       "  0.2916452884674072,\n",
       "  0.2952699363231659,\n",
       "  0.29102417826652527,\n",
       "  0.29856112599372864,\n",
       "  0.2889534533023834,\n",
       "  0.2816350758075714,\n",
       "  0.2991770803928375,\n",
       "  0.2944835424423218,\n",
       "  0.299742192029953,\n",
       "  0.30518192052841187,\n",
       "  0.2939690947532654,\n",
       "  0.29878711700439453,\n",
       "  0.29888319969177246,\n",
       "  0.2889416217803955]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T03:19:31.511250Z",
     "start_time": "2021-06-03T03:19:31.496295Z"
    }
   },
   "outputs": [],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T03:19:34.981781Z",
     "start_time": "2021-06-03T03:19:34.776765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bd79bfcbe0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Two: Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:07:26.375877Z",
     "start_time": "2021-06-03T11:07:26.021745Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:07:28.841476Z",
     "start_time": "2021-06-03T11:07:28.830644Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:08:36.164707Z",
     "start_time": "2021-06-03T11:08:36.149682Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:08:53.658491Z",
     "start_time": "2021-06-03T11:08:38.856251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 2s 49ms/step - loss: 0.6961 - val_loss: 0.6706\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6646 - val_loss: 0.6440\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6381 - val_loss: 0.6132\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6016 - val_loss: 0.5716\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5637 - val_loss: 0.5234\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5150 - val_loss: 0.4713\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4469 - val_loss: 0.4195\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4033 - val_loss: 0.3683\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3641 - val_loss: 0.3259\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3354 - val_loss: 0.2883\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3009 - val_loss: 0.2591\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2692 - val_loss: 0.2343\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2336 - val_loss: 0.2195\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2332 - val_loss: 0.2000\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1880 - val_loss: 0.1907\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1718 - val_loss: 0.1774\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1810 - val_loss: 0.1709\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1626 - val_loss: 0.1608\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1517 - val_loss: 0.1624\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1355 - val_loss: 0.1489\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1396 - val_loss: 0.1484\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1203 - val_loss: 0.1413\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1190 - val_loss: 0.1402\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1198 - val_loss: 0.1325\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1174 - val_loss: 0.1312\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1105 - val_loss: 0.1309\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1087 - val_loss: 0.1252\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0952 - val_loss: 0.1262\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1033 - val_loss: 0.1210\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1009 - val_loss: 0.1256\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0965 - val_loss: 0.1169\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0823 - val_loss: 0.1241\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0939 - val_loss: 0.1157\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0920 - val_loss: 0.1199\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0954 - val_loss: 0.1177\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0662 - val_loss: 0.1157\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0926 - val_loss: 0.1138\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.1136\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0692 - val_loss: 0.1141\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0658 - val_loss: 0.1126\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0707 - val_loss: 0.1127\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0742 - val_loss: 0.1092\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0597 - val_loss: 0.1127\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0767 - val_loss: 0.1099\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0657 - val_loss: 0.1112\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0671 - val_loss: 0.1095\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0672 - val_loss: 0.1117\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0586 - val_loss: 0.1101\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0678 - val_loss: 0.1101\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0488 - val_loss: 0.1113\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0585 - val_loss: 0.1077\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0770 - val_loss: 0.1130\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0674 - val_loss: 0.1066\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0542 - val_loss: 0.1128\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0537 - val_loss: 0.1062\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0618 - val_loss: 0.1075\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.1091\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0405 - val_loss: 0.1091\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0558 - val_loss: 0.1084\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0495 - val_loss: 0.1082\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0425 - val_loss: 0.1104\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0544 - val_loss: 0.1056\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0560 - val_loss: 0.1099\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0488 - val_loss: 0.1059\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0507 - val_loss: 0.1062\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0541 - val_loss: 0.1059\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0472 - val_loss: 0.1087\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0529 - val_loss: 0.1061\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0453 - val_loss: 0.1103\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0580 - val_loss: 0.1095\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0553 - val_loss: 0.1082\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0487 - val_loss: 0.1103\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0504 - val_loss: 0.1180\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0437 - val_loss: 0.1040\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0562 - val_loss: 0.1093\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0471 - val_loss: 0.1106\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0467 - val_loss: 0.1089\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0488 - val_loss: 0.1046\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0656 - val_loss: 0.1093\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0380 - val_loss: 0.1056\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0413 - val_loss: 0.1121\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0389 - val_loss: 0.1097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0357 - val_loss: 0.1068\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0467 - val_loss: 0.1108\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0418 - val_loss: 0.1057\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0387 - val_loss: 0.1044\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0362 - val_loss: 0.1129\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0372 - val_loss: 0.1078\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0503 - val_loss: 0.1106\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0486 - val_loss: 0.1033\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.1093\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0468 - val_loss: 0.1140\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0494 - val_loss: 0.1038\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0466 - val_loss: 0.1179\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0395 - val_loss: 0.1025\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0519 - val_loss: 0.1035\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0526 - val_loss: 0.1178\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0610 - val_loss: 0.1073\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0354 - val_loss: 0.1104\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0575 - val_loss: 0.1031\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0491 - val_loss: 0.1092\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0440 - val_loss: 0.1067\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.1028\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0537 - val_loss: 0.1130\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.1094\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0324 - val_loss: 0.1077\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0518 - val_loss: 0.1033\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0348 - val_loss: 0.1119\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0319 - val_loss: 0.1091\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0396 - val_loss: 0.1078\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0403 - val_loss: 0.1088\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0349 - val_loss: 0.1081\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0567 - val_loss: 0.1067\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0499 - val_loss: 0.1142\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0405 - val_loss: 0.1030\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0430 - val_loss: 0.1087\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0520 - val_loss: 0.1119\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0419 - val_loss: 0.1092\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.1078\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0517 - val_loss: 0.1048\n",
      "Epoch 00120: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bd79ce7490>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:09:05.548311Z",
     "start_time": "2021-06-03T11:09:05.098807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bd7b079910>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Three: Adding in DropOut Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:09:53.012692Z",
     "start_time": "2021-06-03T11:09:53.008113Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:10:10.242415Z",
     "start_time": "2021-06-03T11:10:10.192470Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:10:29.181377Z",
     "start_time": "2021-06-03T11:10:13.600941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.7158 - val_loss: 0.6578\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6294\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6726 - val_loss: 0.6020\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6206 - val_loss: 0.5777\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6300 - val_loss: 0.5533\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5950 - val_loss: 0.5279\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5555 - val_loss: 0.4995\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5565 - val_loss: 0.4729\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5151 - val_loss: 0.4538\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5316 - val_loss: 0.4330\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4942 - val_loss: 0.4090\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4825 - val_loss: 0.3857\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4353 - val_loss: 0.3708\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4584 - val_loss: 0.3534\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4324 - val_loss: 0.3313\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4288 - val_loss: 0.3175\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4106 - val_loss: 0.3083\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3966 - val_loss: 0.2936\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3873 - val_loss: 0.2774\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3596 - val_loss: 0.2589\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.3474 - val_loss: 0.2447\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3854 - val_loss: 0.2338\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3547 - val_loss: 0.2264\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3433 - val_loss: 0.2157\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3209 - val_loss: 0.2082\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3079 - val_loss: 0.2079\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2619 - val_loss: 0.1938\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2910 - val_loss: 0.1859\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.3031 - val_loss: 0.1866\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2822 - val_loss: 0.1843\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2519 - val_loss: 0.1775\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2261 - val_loss: 0.1649\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2459 - val_loss: 0.1643\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2744 - val_loss: 0.1538\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2697 - val_loss: 0.1568\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2223 - val_loss: 0.1580\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2540 - val_loss: 0.1508\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2397 - val_loss: 0.1459\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.220 - 0s 7ms/step - loss: 0.2161 - val_loss: 0.1451\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2058 - val_loss: 0.1466\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2524 - val_loss: 0.1357\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1897 - val_loss: 0.1358\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2170 - val_loss: 0.1458\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2191 - val_loss: 0.1358\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1812 - val_loss: 0.1319\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2000 - val_loss: 0.1327\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1819 - val_loss: 0.1254\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2173 - val_loss: 0.1320\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1656 - val_loss: 0.1294\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2033 - val_loss: 0.1222\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1710 - val_loss: 0.1216\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1891 - val_loss: 0.1174\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1721 - val_loss: 0.1189\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1685 - val_loss: 0.1150\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1741 - val_loss: 0.1133\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1512 - val_loss: 0.1246\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1495 - val_loss: 0.1165\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1533 - val_loss: 0.1123\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1483 - val_loss: 0.1154\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1607 - val_loss: 0.1105\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1304 - val_loss: 0.1099\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1402 - val_loss: 0.1128\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1525 - val_loss: 0.1120\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1884 - val_loss: 0.1108\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1937 - val_loss: 0.1073\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1532 - val_loss: 0.1124\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1399 - val_loss: 0.1095\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1957 - val_loss: 0.1070\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1316 - val_loss: 0.1108\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1240 - val_loss: 0.1057\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1336 - val_loss: 0.1098\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1315 - val_loss: 0.1080\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1628 - val_loss: 0.1062\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1817 - val_loss: 0.1136\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1374 - val_loss: 0.1089\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1245 - val_loss: 0.1105\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1167 - val_loss: 0.1061\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1455 - val_loss: 0.1054\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1921 - val_loss: 0.1039\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1115 - val_loss: 0.1055\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1121 - val_loss: 0.1139\n",
      "Epoch 82/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1505 - val_loss: 0.1083\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1050 - val_loss: 0.1076\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1078 - val_loss: 0.1135\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1345 - val_loss: 0.1063\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1365 - val_loss: 0.1053\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1066 - val_loss: 0.1057\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1256 - val_loss: 0.1021\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1266 - val_loss: 0.1098\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1134 - val_loss: 0.1153\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1093 - val_loss: 0.1077\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0895 - val_loss: 0.1082\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1062 - val_loss: 0.1081\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1020 - val_loss: 0.1102\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1294 - val_loss: 0.1050\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1153 - val_loss: 0.1016\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1183 - val_loss: 0.1088\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0889 - val_loss: 0.1013\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1123 - val_loss: 0.1151\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1264 - val_loss: 0.1114\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1070 - val_loss: 0.1000\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1019 - val_loss: 0.1065\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0767 - val_loss: 0.1127\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1235 - val_loss: 0.1157\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1125 - val_loss: 0.1106\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0812 - val_loss: 0.1065\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0967 - val_loss: 0.1025\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1306 - val_loss: 0.1105\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1155 - val_loss: 0.1042\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1139 - val_loss: 0.1052\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1243 - val_loss: 0.1001\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0986 - val_loss: 0.1066\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0960 - val_loss: 0.1130\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1041 - val_loss: 0.1150\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1210 - val_loss: 0.1028\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1193 - val_loss: 0.1020\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0892 - val_loss: 0.1016\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1152 - val_loss: 0.1100\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0931 - val_loss: 0.1061\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1003 - val_loss: 0.1305\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1013 - val_loss: 0.1115\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0935 - val_loss: 0.1044\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0812 - val_loss: 0.1050\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1161 - val_loss: 0.1024\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1526 - val_loss: 0.1216\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0909 - val_loss: 0.1148\n",
      "Epoch 00126: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bd7b114c40>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:10:37.036820Z",
     "start_time": "2021-06-03T11:10:36.717864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bd784240a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:11:01.225902Z",
     "start_time": "2021-06-03T11:11:00.970802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:11:05.270952Z",
     "start_time": "2021-06-03T11:11:05.254451Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:11:07.822941Z",
     "start_time": "2021-06-03T11:11:07.807620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        55\n",
      "           1       0.99      0.94      0.97        88\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.95      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T11:11:27.201718Z",
     "start_time": "2021-06-03T11:11:27.180665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  1]\n",
      " [ 5 83]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
